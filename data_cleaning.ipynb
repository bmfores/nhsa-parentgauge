{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f266bcaa",
   "metadata": {},
   "source": [
    "<div style=\"display: inline-block;\">\n",
    "    <img src=\"images/nhsa_logo.png\" alt=\"Image\" style=\"text-align: left;\">\n",
    "</div>\n",
    "\n",
    "# Parent Gauge Data Analysis Project\n",
    "---\n",
    "## Data Cleaning Script and Documentation\n",
    "\n",
    "In this script, we will provide a step-by-step demonstration of how script is being cleaned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "001f86a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.2-cp311-cp311-macosx_11_0_arm64.whl (10.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tzdata>=2022.1 (from pandas)\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.21.0 (from pandas)\n",
      "  Downloading numpy-1.24.3-cp311-cp311-macosx_11_0_arm64.whl (13.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.24.3 pandas-2.0.2 pytz-2023.3 tzdata-2023.3\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "#install necessary libraries for data cleaning.\n",
    "!pip3 install pandas\n",
    "!pip3 install numpy\n",
    "!pip3 install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ada7c4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "880529ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vw/1sthm_ts1dj_1hqg1xnsz19w0000gn/T/ipykernel_83954/2594145135.py:8: DtypeWarning: Columns (16,18,27,35,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,92) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('intv_data.csv')\n"
     ]
    }
   ],
   "source": [
    "#Load the Data into the dataframe\n",
    "df = pd.read_excel('INTVDATA.xlsx', sheet_name ='Main', engine ='openpyxl')\n",
    "\n",
    "#Copy existing dataframe to .csv file\n",
    "df.to_csv(\"intv_data.csv\", index=False)\n",
    "\n",
    "#read the new .csv file\n",
    "df = pd.read_csv('intv_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248b43f5",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fdede69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because the main dataset is too large for data cleaning, \n",
    "#construct a small sample for faster processing\n",
    "df_sample = df.sample(frac=0.08)\n",
    "df_sample.to_csv('sample_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc37ee6",
   "metadata": {},
   "source": [
    "## Main Data Cleaning\n",
    "\n",
    "This is a summary of all the data cleaning and reformatting steps that were conducted.\n",
    "- **Program** - I identified the corresponding state and county.\n",
    "- **Program** - I identified the corresponding state and county.\n",
    "- **Program** - I identified the corresponding state and county.\n",
    "- **Program** - I identified the corresponding state and county.\n",
    "- **Program** - I identified the corresponding state and county.\n",
    "- **Program** - I identified the corresponding state and county.\n",
    "- **Program** - I identified the corresponding state and county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "87120f5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['guardian_vendor_id', 'interview_id', 'interviewer_id', 'interviewer', 'interviewer_vendor_id', 'student_staff_vendor_id', 'student_vendor_id'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m columns_to_remove \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mguardian_vendor_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterview_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterviewer_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      7\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterviewer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterviewer_vendor_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstudent_staff_vendor_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      8\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstudent_vendor_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Removing the columns from the DataFrame\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m df_sample \u001b[38;5;241m=\u001b[39m \u001b[43mdf_sample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns_to_remove\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#save updates to working csv\u001b[39;00m\n\u001b[1;32m     14\u001b[0m df_sample\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5112\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5122\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5123\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5256\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5260\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5264\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5265\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5266\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4549\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4589\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4591\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4592\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4594\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:6696\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6695\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6696\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6697\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6698\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['guardian_vendor_id', 'interview_id', 'interviewer_id', 'interviewer', 'interviewer_vendor_id', 'student_staff_vendor_id', 'student_vendor_id'] not found in axis\""
     ]
    }
   ],
   "source": [
    "##REMOVE UNNECESSARY COLUMNS\n",
    "# guardian_vendor_id, interview_id, interviewer_id, interviewer,\n",
    "#interviewer_vendor_id, student_staff_vendor_id, student_vendor_id\n",
    "\n",
    "# List of columns to be removed\n",
    "columns_to_remove = ['guardian_vendor_id', 'interview_id', 'interviewer_id', \n",
    "                     'interviewer', 'interviewer_vendor_id', 'student_staff_vendor_id', \n",
    "                     'student_vendor_id']\n",
    "\n",
    "# Removing the columns from the DataFrame\n",
    "df_sample = df_sample.drop(columns=columns_to_remove)\n",
    "\n",
    "#save updates to working csv\n",
    "df_sample.to_csv('sample_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36f9bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##code to clean\n",
    "##PROGRAM\n",
    "unique_programs = df_sample['program'].unique().tolist()\n",
    "\n",
    "# Sort the list in place\n",
    "unique_programs.sort()\n",
    "\n",
    "#create a text file of the unique programs\n",
    "with open('unique_programs.txt', 'w') as f:\n",
    "    for item in unique_programs:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e79c18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##DATE##\n",
    "# Convert 'date' column to datetime format\n",
    "#errors=coercse converts problematic dates to NaN.\n",
    "#df['date'] = pd.to_datetime(df['date'], format='mixed', errors='coerce')\n",
    "#print(df['date'].isnull().sum())\n",
    "\n",
    "# Make a copy of the 'date' column\n",
    "#df_copy = df['date'].copy()\n",
    "\n",
    "# Iterate over the entries in the 'date' column\n",
    "for i, date in enumerate(df_sample['date']):\n",
    "    try:\n",
    "        # Try to convert the date to datetime format\n",
    "        pd.to_datetime(date, format='mixed')\n",
    "    except Exception:\n",
    "        print(f\"An error occurred at index {i} with the date: {date}\")\n",
    "        \n",
    "df_sample['date'] = pd.to_datetime(df_sample['date'], errors='coerce')\n",
    "\n",
    "#Create separate 'year', 'month', and 'day' columns\n",
    "df_sample['year'] = df_sample['date'].dt.year\n",
    "df_sample['month'] = df_sample['date'].dt.month\n",
    "df_sample['day'] = df_sample['date'].dt.day\n",
    "\n",
    "#save to csv\n",
    "df_sample.to_csv('sample_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb51bf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0.1', 'Unnamed: 0', 'center', 'created_at', 'date',\n",
      "       'evaluation_year', 'guardian', 'guardian_employment',\n",
      "       'guardian_enrollment_date', 'guardian_highest_education',\n",
      "       ...\n",
      "       'OQ7', 'OQ8', 'OQ9', 'year', 'month', 'day', 'evaluation_Initial',\n",
      "       'evaluation_Midyear', 'evaluation_Post', 'evaluation_evaluation'],\n",
      "      dtype='object', length=107)\n"
     ]
    }
   ],
   "source": [
    "##Evaluation##\n",
    "#use one-hot encoding to create dummy variables in preparation for regression.\n",
    "#NOTE: This, however eliminates the original 'evaluation' column\n",
    "df_sample = pd.get_dummies(df_sample, columns=['evaluation'])\n",
    "\n",
    "#save updates to csv\n",
    "df_sample.to_csv('sample_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "70434815",
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluation_year##\n",
    "# Split the 'evaluation_year' column into two separate columns 'start_year' and 'end_year'\n",
    "df_sample[['evaluation_start_year', 'evaluation_end_year']] = df_sample['evaluation_year'].str.split('-', expand=True)\n",
    "\n",
    "#save updates to csv\n",
    "df_sample.to_csv('sample_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48824aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "##guardian_birth_date##\n",
    "#– use DOB and interview year to determine guardian’s age during time of interview. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab4ddf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "##guardian_sex##\n",
    "# Using direct mapping to create dummy variable out of guardian_sex\n",
    "df_sample['female'] = (df_sample['guardian_sex'] == 'Female').astype(int)\n",
    "\n",
    "#save updates to csv\n",
    "df_sample.to_csv('sample_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7fb2c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
