{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f266bcaa",
   "metadata": {},
   "source": [
    "<div style=\"display: inline-block;\">\n",
    "    <img src=\"images/nhsa_logo.png\" alt=\"Image\" style=\"text-align: left;\">\n",
    "</div>\n",
    "\n",
    "# Parent Gauge Data Analysis Project\n",
    "---\n",
    "## Data Wrangling Script and Documentation\n",
    "\n",
    "In this script, we will provide a step-by-step demonstration of how script is being cleaned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ada7c4d0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start with the necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "880529ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vw/1sthm_ts1dj_1hqg1xnsz19w0000gn/T/ipykernel_9284/813791575.py:8: DtypeWarning: Columns (16,18,27,35,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,92) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data/intv_data.csv')\n"
     ]
    }
   ],
   "source": [
    "#Load the Data into the dataframe\n",
    "df = pd.read_excel('../data/INTVDATA.xlsx', sheet_name ='Main', engine ='openpyxl')\n",
    "\n",
    "#Copy existing dataframe to .csv file\n",
    "df.to_csv('../data/intv_data.csv', index=False)\n",
    "\n",
    "#read the new .csv file\n",
    "df = pd.read_csv('../data/intv_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248b43f5",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb847af-89c4-4385-b576-a29fd0615f11",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Drop Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b05f7da0-19b2-4c92-bfef-9e340735cb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows dropped: 203\n"
     ]
    }
   ],
   "source": [
    "####DROP DUPLICATE ROWS####\n",
    "# Count the number of rows before dropping duplicates\n",
    "rows_before = len(df)\n",
    "\n",
    "# Drop duplicate rows based on all columns except the first two\n",
    "result = df.drop_duplicates(subset=df.columns[2:])\n",
    "\n",
    "# Count the number of rows after dropping duplicates\n",
    "rows_after = len(result)\n",
    "\n",
    "# Calculate and print the number of rows dropped\n",
    "rows_dropped = rows_before - rows_after\n",
    "print(f\"Number of rows dropped: {rows_dropped}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aefeac-e571-4881-8a0a-ab1a8b21ad62",
   "metadata": {},
   "source": [
    "## Sample Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdede69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a sample of 8% of the total dataset\n"
     ]
    }
   ],
   "source": [
    "#Because the main dataset is too large for data cleaning, \n",
    "#construct a small sample for faster processing. Once I am done coding, we will use the entire dataset.\n",
    "df_sample = df.sample(frac=0.08)\n",
    "df_sample.to_csv('../data/sample_data.csv', index=False)\n",
    "\n",
    "print(\"Created a sample of 8% of the total dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc37ee6",
   "metadata": {},
   "source": [
    "## Main Data Cleaning\n",
    "\n",
    "This is a summary of all the data cleaning and reformatting steps that were conducted.\n",
    "- **Program** - I identified the corresponding state and county.\n",
    "- **Program** - I identified the corresponding state and county.\n",
    "- **Program** - I identified the corresponding state and county.\n",
    "- **Program** - I identified the corresponding state and county.\n",
    "- **Program** - I identified the corresponding state and county.\n",
    "- **Program** - I identified the corresponding state and county.\n",
    "- **Program** - I identified the corresponding state and county."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c982584-5ab9-4fbd-87eb-ca08857a01c1",
   "metadata": {},
   "source": [
    "## Remove Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87120f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##REMOVE UNNECESSARY COLUMNS\n",
    "# guardian_vendor_id, interview_id, interviewer_id, interviewer,\n",
    "#interviewer_vendor_id, student_staff_vendor_id, student_vendor_id\n",
    "\n",
    "# List of columns to be removed\n",
    "columns_to_remove = ['guardian_vendor_id', 'interview_id', 'interviewer_id', \n",
    "                     'interviewer', 'interviewer_vendor_id', 'student_staff_vendor_id', \n",
    "                     'student_vendor_id']\n",
    "\n",
    "# Removing the columns from the DataFrame\n",
    "df_sample = df_sample.drop(columns=columns_to_remove)\n",
    "\n",
    "#save updates to working csv\n",
    "df_sample.to_csv('../data/sample_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d067236d-26f6-4dcf-98b9-e9b68751588b",
   "metadata": {},
   "source": [
    "# Code to Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce77e40-2bab-49b2-b109-695cd4b10243",
   "metadata": {},
   "source": [
    "## Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36f9bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##code to clean\n",
    "##PROGRAM\n",
    "unique_programs = df_sample['program'].unique().tolist()\n",
    "\n",
    "# Sort the list in place\n",
    "unique_programs.sort()\n",
    "\n",
    "#create a text file of the unique programs\n",
    "with open('../data/unique_programs.txt', 'w') as f:\n",
    "    for item in unique_programs:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed9231c-5aba-4b41-b54f-5b91242b2d42",
   "metadata": {},
   "source": [
    "## Created_at"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04603ece-23cd-4ff9-aa5d-daee20bde4de",
   "metadata": {},
   "source": [
    "## Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e79c18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred at index 339 with the date: date\n",
      "An error occurred at index 531 with the date: date\n",
      "An error occurred at index 881 with the date: date\n",
      "An error occurred at index 953 with the date: date\n",
      "An error occurred at index 961 with the date: date\n",
      "An error occurred at index 1372 with the date: date\n",
      "An error occurred at index 4517 with the date: date\n",
      "An error occurred at index 6454 with the date: date\n",
      "An error occurred at index 8159 with the date: date\n",
      "An error occurred at index 10415 with the date: date\n",
      "An error occurred at index 10559 with the date: date\n",
      "An error occurred at index 10634 with the date: date\n",
      "An error occurred at index 10764 with the date: date\n",
      "An error occurred at index 11479 with the date: date\n",
      "An error occurred at index 11577 with the date: date\n",
      "An error occurred at index 14098 with the date: date\n",
      "An error occurred at index 14340 with the date: date\n",
      "An error occurred at index 14387 with the date: date\n",
      "An error occurred at index 14719 with the date: date\n",
      "An error occurred at index 14895 with the date: date\n",
      "An error occurred at index 15024 with the date: date\n"
     ]
    }
   ],
   "source": [
    "##DATE##\n",
    "# Convert 'date' column to datetime format\n",
    "#errors=coercse converts problematic dates to NaN.\n",
    "#df['date'] = pd.to_datetime(df['date'], format='mixed', errors='coerce')\n",
    "#print(df['date'].isnull().sum())\n",
    "\n",
    "# Make a copy of the 'date' column\n",
    "#df_copy = df['date'].copy()\n",
    "\n",
    "# Iterate over the entries in the 'date' column\n",
    "for i, date in enumerate(df_sample['date']):\n",
    "    try:\n",
    "        # Try to convert the date to datetime format\n",
    "        pd.to_datetime(date, format='mixed')\n",
    "    except Exception:\n",
    "        print(f\"An error occurred at index {i} with the date: {date}\")\n",
    "        \n",
    "df_sample['date'] = pd.to_datetime(df_sample['date'], errors='coerce')\n",
    "\n",
    "#Create separate 'year', 'month', and 'day' columns\n",
    "df_sample['year'] = df_sample['date'].dt.year\n",
    "df_sample['month'] = df_sample['date'].dt.month\n",
    "df_sample['day'] = df_sample['date'].dt.day\n",
    "\n",
    "#save to csv\n",
    "df_sample.to_csv('../data/sample_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe3600a-9e0d-45bb-8b0d-dabedd5d447b",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Dummy variables have been created, breaking the three categorical variables into three columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb51bf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluation##\n",
    "#use one-hot encoding to create dummy variables in preparation for regression.\n",
    "#NOTE: This, however eliminates the original 'evaluation' column\n",
    "df_sample = pd.get_dummies(df_sample, columns=['evaluation'])\n",
    "\n",
    "#save updates to csv\n",
    "df_sample.to_csv('../data/sample_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dea179-7f4f-4d83-8aea-1a15e8aabb91",
   "metadata": {},
   "source": [
    "## Evaluation Year\n",
    "\n",
    "The original format of the evaluation year was formatted as 2016-2017. For easier analysis, the start and end year have been split up into two columns, \"evaluation_start_year\" and \"evaluation_end_year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70434815",
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluation_year##\n",
    "# Split the 'evaluation_year' column into two separate columns 'start_year' and 'end_year'\n",
    "df_sample[['evaluation_start_year', 'evaluation_end_year']] = df_sample['evaluation_year'].str.split('-', expand=True)\n",
    "\n",
    "#save updates to csv\n",
    "df_sample.to_csv('../data/sample_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c91907a-6497-4597-b2fa-51833440742e",
   "metadata": {},
   "source": [
    "## Guardian Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f887bb-2262-4dce-b97f-51dcf103d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##need to scrub the name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d3562b-8532-4949-9da0-715f7d47dd6e",
   "metadata": {},
   "source": [
    "## Guardian Employment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c75ec11-d8cb-4c4b-8708-8ad9f2afa55e",
   "metadata": {},
   "source": [
    "## Guardian Enrollment Date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60356e33-2ece-47e9-9fec-f3b3621ccc1a",
   "metadata": {},
   "source": [
    "## Guardian Highest Education"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91308fcc-6658-46b1-8b79-e0d99dea5e2d",
   "metadata": {},
   "source": [
    "## Guardian, Hispanic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cf8fc10-fd5d-4859-84e6-ea606898c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##remove anything that is not \"yes\" or \"no\"\n",
    "# Update the guardian_hispanic column\n",
    "df_sample.loc[~df_sample[\"guardian_hispanic\"].isin([\"Yes\", \"No\"]), \"guardian_hispanic\"] = \"\"\n",
    "\n",
    "#check the column \"guardian_native_language\" \"student_hispanic\", \n",
    "#\"student_native_language\", \"language of interview\", \n",
    "# Define a function to fill missing values in guardian_hispanic column based on conditions\n",
    "def fill_guardian_hispanic(row):\n",
    "    if pd.isnull(row['guardian_hispanic']):\n",
    "        if row['student_hispanic'] == 'Yes':\n",
    "            return 'Yes'\n",
    "        elif row['student_hispanic'] == 'No':\n",
    "            return 'No'\n",
    "        elif row['guardian_native_language'] == 'Spanish':\n",
    "            return 'Yes'\n",
    "        elif row['student_native_language'] == 'Spanish':\n",
    "            return 'Yes'\n",
    "        elif row['language'] == 'Spanish':\n",
    "            return 'Yes'\n",
    "        else:\n",
    "            return 'No'\n",
    "    else:\n",
    "        return row['guardian_hispanic']\n",
    "\n",
    "# Apply the function to fill missing values in guardian_hispanic column\n",
    "df_sample['guardian_hispanic'] = df_sample.apply(fill_guardian_hispanic, axis=1)\n",
    "\n",
    "##---------------------------##\n",
    "\n",
    "# Convert \"yes\" and \"no\" to binary dummy variables\n",
    "#df_sample = pd.get_dummies(df_sample, columns=[\"guardian_hispanic\"], prefix=\"guardian_hispanic\", drop_first=True)\n",
    "\n",
    "# Write the updated data to a new CSV file\n",
    "df_sample.to_csv('../data/sample_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6765367-b42f-4132-a26e-d852345480de",
   "metadata": {},
   "source": [
    "## Guardian Native Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a92fbe-0191-4258-a1a7-5d4fa4b0e2f8",
   "metadata": {},
   "source": [
    "## Guardian Race"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf201ede-9c7f-4763-9d8c-d792f76f4a1e",
   "metadata": {},
   "source": [
    "## Guardian Birth Date???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48824aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "##guardian_birth_date##\n",
    "#– use DOB and interview year to determine guardian’s age during time of interview. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008b7e9-9333-4e1c-b5e2-7a5285052490",
   "metadata": {},
   "source": [
    "## Guardian Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a24b3bf-626e-493d-a0fd-0fe7aea4156c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing rows in 'sex' column: 503\n"
     ]
    }
   ],
   "source": [
    "# Count the number of missing rows in 'guardian_hispanic' column\n",
    "missing_count = df_sample['guardian_sex'].isnull().sum()\n",
    "\n",
    "# Print the number of missing rows\n",
    "print(\"Number of missing rows in 'sex' column:\", missing_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab4ddf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "##guardian_sex##\n",
    "# Using direct mapping to create dummy variable out of guardian_sex\n",
    "df_sample['female'] = (df_sample['guardian_sex'] == 'Female').astype(int)\n",
    "\n",
    "#save updates to csv\n",
    "df_sample.to_csv('../data/sample_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c051d4-09b8-4a7f-ac1e-99568cf937c0",
   "metadata": {},
   "source": [
    "## Guardian Vendor ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186ff1a3-2d2b-45fe-a196-43733ee1493b",
   "metadata": {},
   "source": [
    "## Interview ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa45a88d-0e72-49c2-93db-ceb3e40e2f43",
   "metadata": {},
   "source": [
    "## Interviewer Name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00e7015-af4b-4f45-839a-aaa8126e0974",
   "metadata": {},
   "source": [
    "## Interviewer ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a571618f-6aa2-49a7-b219-4598690a8a2d",
   "metadata": {},
   "source": [
    "## Interviewer Vendor ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086bb666-c052-4c9a-a373-7a2638ddf708",
   "metadata": {},
   "source": [
    "## Language of Interview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c820c9b2-5124-4242-9cfd-7c0c568ff999",
   "metadata": {},
   "source": [
    "## Mode of Interview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feca48e3-011c-40fa-80af-e53e44b0d3b0",
   "metadata": {},
   "source": [
    "## Program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778d4b94-f760-4f48-8314-2e352a8a0ee9",
   "metadata": {},
   "source": [
    "## Student Name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0d460a-4967-4f05-ae00-2384c66eb7ed",
   "metadata": {},
   "source": [
    "## Student Enrollment Date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72db8661-9234-4a9e-8585-81f63f07fd08",
   "metadata": {},
   "source": [
    "## Student Disability Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "723b93ec-c71e-40f9-b34a-a980b54da879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing rows in 'student_hispanic' column: 1129\n"
     ]
    }
   ],
   "source": [
    "# Count the number of missing rows in 'guardian_hispanic' column\n",
    "missing_count = df_sample['student_hispanic'].isnull().sum()\n",
    "\n",
    "# Print the number of missing rows\n",
    "print(\"Number of missing rows in 'student_hispanic' column:\", missing_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb6f308-0d54-4e57-a7df-9144cee7c5dd",
   "metadata": {},
   "source": [
    "## Student, Hispanic\n",
    "##remove anything that is not \"yes\" or \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd96b756-0128-4ce0-976d-9ed748f4de98",
   "metadata": {},
   "outputs": [],
   "source": [
    "##remove anything that is not \"yes\" or \"no\"\n",
    "# Update the guardian_hispanic column\n",
    "df_sample.loc[~df_sample[\"guardian_hispanic\"].isin([\"Yes\", \"No\"]), \"guardian_hispanic\"] = \"\"\n",
    "\n",
    "#check the column \"guardian_native_language\" \"guardian_hispanic\", \"student_native_language\"\n",
    "# Define a function to fill missing values in student_hispanic column based on conditions\n",
    "def fill_student_hispanic(row):\n",
    "    if pd.isnull(row['student_hispanic']):\n",
    "        if row['guardian_hispanic'] == 'Yes':\n",
    "            return 'Yes'\n",
    "        elif row['guardian_hispanic'] == 'No':\n",
    "            return 'No'\n",
    "        elif row['guardian_native_language'] == 'Spanish':\n",
    "            return 'Yes'\n",
    "        elif row['student_native_language'] == 'Spanish':\n",
    "            return 'Yes'\n",
    "        elif pd.notnull(row['student_native_language']):\n",
    "            return 'No'\n",
    "        else:\n",
    "            return ''\n",
    "    else:\n",
    "        return row['student_hispanic']\n",
    "\n",
    "# Apply the function to fill missing values in student_hispanic column\n",
    "df_sample['student_hispanic'] = df_sample.apply(fill_student_hispanic, axis=1)\n",
    "\n",
    "##---------------------------##\n",
    "\n",
    "# Convert \"yes\" and \"no\" to binary dummy variables\n",
    "#df_sample = pd.get_dummies(df_sample, columns=[\"guardian_hispanic\"], prefix=\"guardian_hispanic\", drop_first=True)\n",
    "\n",
    "# Write the updated data to a new CSV file\n",
    "df_sample.to_csv('../data/sample_data.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b218699-95ec-4e6b-a7ae-74b31d48bb5e",
   "metadata": {},
   "source": [
    "## Student, ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033d3621-4b56-45a5-8328-971053cb8350",
   "metadata": {},
   "source": [
    "## Student Birth Date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392b75e0-4753-4a15-8d2d-068d65477886",
   "metadata": {},
   "source": [
    "## Student in last year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d5fbc1-5ea4-4de7-ad32-6a3c9b995b47",
   "metadata": {},
   "source": [
    "## Student Native Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941a46cb-a2b7-4d1b-91b4-c6f5ca63f617",
   "metadata": {},
   "source": [
    "## Student Program Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d19ee73-5275-450c-bddd-98476604d5dc",
   "metadata": {},
   "source": [
    "## Student Race"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bb8856-0702-4e8c-9eed-aba58ec89b13",
   "metadata": {},
   "source": [
    "## Student Service Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76a8e69-c4e4-4d25-8c87-cc9ce23bd330",
   "metadata": {},
   "source": [
    "## Student Sex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930fc8f9-47e2-4a3f-9ca2-24d4a9609aa1",
   "metadata": {},
   "source": [
    "## Student Staff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82383d2-47ab-4d3f-80e5-93fbdc3153af",
   "metadata": {},
   "source": [
    "## Student Staff ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5341642f-841e-4452-ba8a-2c893685dfe3",
   "metadata": {},
   "source": [
    "## Student Staff Vendor ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df0c85e-4433-49e5-9525-61515f73a7e0",
   "metadata": {},
   "source": [
    "## Student Vendor ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82471932-cc4a-45ec-8ee2-5a62ff5b2c9c",
   "metadata": {},
   "source": [
    "## Student Was Early Headstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83ef1b7-0e2a-4ab1-a3b4-1771c58c7509",
   "metadata": {},
   "source": [
    "## Student Was Head Start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ece5bc2-d63b-41d6-97b7-d63da2e8f1db",
   "metadata": {},
   "source": [
    "# Next Section: Likert Scale Interview Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48861bb-06fb-4a18-a50d-8829862a282b",
   "metadata": {},
   "source": [
    "# Next Section: Open Interview Questions\n",
    "\n",
    "perhaps we can use data analysis to see how sentiments change\n",
    "https://www.surveypractice.org/article/25699-what-to-do-with-all-those-open-ended-responses-data-visualization-techniques-for-survey-researchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573f5a74-e6d5-4ad7-adc1-cbfe26822685",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
